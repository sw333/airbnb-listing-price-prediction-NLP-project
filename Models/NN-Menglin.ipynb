{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NN-Menglin.ipynb","provenance":[],"authorship_tag":"ABX9TyNmLbP2nlk6o4uDTVU/mibk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"w9sBp7EAMb_d","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"outputId":"fbfde453-3941-4da3-f5ff-d169df1285b6","executionInfo":{"status":"ok","timestamp":1586762758247,"user_tz":-480,"elapsed":23597,"user":{"displayName":"17Y6C23 HUANG MENGLIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJasejKAJFhdRWMOIjPCMpYUDk2lCxKSZvZ6xbsA=s64","userId":"02182338258803754528"}}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JUflp3n-N5Ww","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4tzup5wJN600","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"3900f2b3-e2c9-495d-9073-ee76293bf4e6","executionInfo":{"status":"ok","timestamp":1586762763460,"user_tz":-480,"elapsed":5171,"user":{"displayName":"17Y6C23 HUANG MENGLIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJasejKAJFhdRWMOIjPCMpYUDk2lCxKSZvZ6xbsA=s64","userId":"02182338258803754528"}}},"source":["pathlistings = '/content/gdrive/My Drive/BT4222 project/Feature Engineering Data/2yrslistings_seasonality_topic_amenity_sentiment_attraction_cleaned.csv'\n","df_listings_dummy = pd.read_csv(pathlistings)\n","df_listings_dummy.drop(columns=['Unnamed: 0'], inplace=True)\n","\n","X = df_listings_dummy.drop(columns=['price'])\n","y = df_listings_dummy.price\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n","print(X_train.shape)\n","print(X_test.shape)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["(74992, 313)\n","(24998, 313)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y_zfMeJVPYXz","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","plt.style.use('ggplot')\n","\n","def plot_history(history):\n","    # acc = history.history['acc']\n","    # val_acc = history.history['val_acc']\n","    loss = history.history['loss']\n","    val_loss = history.history['val_loss']\n","    x = range(1, len(acc) + 1)\n","\n","    plt.figure(figsize=(12, 5))\n","    # plt.subplot(1, 2, 1)\n","    # plt.plot(x, acc, 'b', label='Training acc')\n","    # plt.plot(x, val_acc, 'r', label='Validation acc')\n","    # plt.title('Training and validation accuracy')\n","    # plt.legend()\n","    # plt.subplot(1, 2, 2)\n","    plt.plot(x, loss, 'b', label='Training loss')\n","    plt.plot(x, val_loss, 'r', label='Validation loss')\n","    plt.title('Training and validation loss')\n","    plt.legend()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X2SE40MBOFy_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":950},"outputId":"bfd052a7-31bc-4501-a418-279792a72417","executionInfo":{"status":"ok","timestamp":1586765198166,"user_tz":-480,"elapsed":294134,"user":{"displayName":"17Y6C23 HUANG MENGLIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJasejKAJFhdRWMOIjPCMpYUDk2lCxKSZvZ6xbsA=s64","userId":"02182338258803754528"}}},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Activation, Flatten\n","\n","NN_model = Sequential()\n","\n","# The Input Layer:\n","NN_model.add(Dense(10, kernel_initializer='normal', input_dim = X_train.shape[1], activation='relu'))\n","\n","# The Hidden Layers :\n","# NN_model.add(Dense(10, kernel_initializer='normal',activation='relu'))\n","\n","# The Output Layer :\n","NN_model.add(Dense(1, kernel_initializer='normal'))\n","\n","# Compile the network :\n","NN_model.compile(loss='mean_squared_error', optimizer='adam')\n","NN_model.summary()\n","\n","# fit the model\n","history = NN_model.fit(X_train, y_train, epochs=20, batch_size=5, validation_split = 0.1)\n","\n","#redictions = NN_model.predict(test)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Model: \"sequential_8\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_22 (Dense)             (None, 10)                3140      \n","_________________________________________________________________\n","dense_23 (Dense)             (None, 1)                 11        \n","=================================================================\n","Total params: 3,151\n","Trainable params: 3,151\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 67492 samples, validate on 7500 samples\n","Epoch 1/20\n","67492/67492 [==============================] - 15s 217us/step - loss: 420460055.2565 - val_loss: 3006088.2931\n","Epoch 2/20\n","67492/67492 [==============================] - 15s 215us/step - loss: 61523458.0853 - val_loss: 24217894466.2250\n","Epoch 3/20\n","67492/67492 [==============================] - 15s 216us/step - loss: 140369577.7127 - val_loss: 1117120081.8613\n","Epoch 4/20\n","67492/67492 [==============================] - 14s 208us/step - loss: 11593727.7628 - val_loss: 4871139635.3071\n","Epoch 5/20\n","67492/67492 [==============================] - 14s 212us/step - loss: 34169833.1844 - val_loss: 23320573929.8475\n","Epoch 6/20\n","67492/67492 [==============================] - 15s 219us/step - loss: 41083922.5008 - val_loss: 1543244258.2490\n","Epoch 7/20\n","67492/67492 [==============================] - 15s 224us/step - loss: 80616736.5888 - val_loss: 23905662013.6938\n","Epoch 8/20\n","67492/67492 [==============================] - 15s 220us/step - loss: 108350706.2541 - val_loss: 132310862645.0991\n","Epoch 9/20\n","67492/67492 [==============================] - 15s 218us/step - loss: 811910520.9752 - val_loss: 481739771954.7733\n","Epoch 10/20\n","67492/67492 [==============================] - 15s 217us/step - loss: 610902330.1280 - val_loss: 3080740644.2143\n","Epoch 11/20\n","67492/67492 [==============================] - 15s 215us/step - loss: 91080505.3945 - val_loss: 16989154187.8394\n","Epoch 12/20\n","67492/67492 [==============================] - 14s 214us/step - loss: 25313359045.8338 - val_loss: 126667242118.0713\n","Epoch 13/20\n","67492/67492 [==============================] - 15s 217us/step - loss: 2473661954.5801 - val_loss: 308013175812.9897\n","Epoch 14/20\n","67492/67492 [==============================] - 15s 223us/step - loss: 89792244057.1969 - val_loss: 135846414140.0482\n","Epoch 15/20\n","67492/67492 [==============================] - 15s 217us/step - loss: 6451782272.5006 - val_loss: 957713919140.3524\n","Epoch 16/20\n","67492/67492 [==============================] - 15s 219us/step - loss: 1651010897.4096 - val_loss: 3472578864826.9009\n","Epoch 17/20\n","67492/67492 [==============================] - 15s 218us/step - loss: 10180786391.1376 - val_loss: 127448969753.7459\n","Epoch 18/20\n","67492/67492 [==============================] - 15s 217us/step - loss: 687708869.3407 - val_loss: 190492490889.3231\n","Epoch 19/20\n","67492/67492 [==============================] - 15s 219us/step - loss: 536664893.0400 - val_loss: 17799703169.4896\n","Epoch 20/20\n","67492/67492 [==============================] - 14s 214us/step - loss: 23321951567.9449 - val_loss: 3436054876.7841\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zDO_88s1Ps0U","colab_type":"code","colab":{}},"source":["plot_history(history)"],"execution_count":0,"outputs":[]}]}